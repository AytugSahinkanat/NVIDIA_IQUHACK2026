{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ur2RoR4QpWlU",
    "outputId": "55212a5e-4d52-4b0e-873d-4061e945c429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cudaq\n",
      "  Downloading cudaq-0.13.0.tar.gz (9.2 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting cuda-quantum-cu12==0.13.0 (from cudaq)\n",
      "  Downloading cuda_quantum_cu12-0.13.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting astpretty~=3.0 (from cuda-quantum-cu12==0.13.0->cudaq)\n",
      "  Downloading astpretty-3.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting custatevec-cu12~=1.10 (from cuda-quantum-cu12==0.13.0->cudaq)\n",
      "  Downloading custatevec_cu12-1.12.0-py3-none-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting cutensornet-cu12~=2.9 (from cuda-quantum-cu12==0.13.0->cudaq)\n",
      "  Downloading cutensornet_cu12-2.11.0-py3-none-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting cudensitymat-cu12~=0.3 (from cuda-quantum-cu12==0.13.0->cudaq)\n",
      "  Downloading cudensitymat_cu12-0.4.0-py3-none-manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (1.16.3)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (2.32.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12~=12.0 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12~=10.3 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12~=12.5 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12~=12.0 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12~=11.4 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12~=12.0 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (12.6.77)\n",
      "Requirement already satisfied: cupy-cuda12x~=13.6.0 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12==0.13.0->cudaq) (13.6.0)\n",
      "Collecting cutensor-cu12<3,>=2.3.1 (from cudensitymat-cu12~=0.3->cuda-quantum-cu12==0.13.0->cudaq)\n",
      "  Downloading cutensor_cu12-2.5.0-py3-none-manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x~=13.6.0->cuda-quantum-cu12==0.13.0->cudaq) (0.8.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12~=11.4->cuda-quantum-cu12==0.13.0->cudaq) (12.6.85)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->cuda-quantum-cu12==0.13.0->cudaq) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->cuda-quantum-cu12==0.13.0->cudaq) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->cuda-quantum-cu12==0.13.0->cudaq) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->cuda-quantum-cu12==0.13.0->cudaq) (2026.1.4)\n",
      "Downloading cuda_quantum_cu12-0.13.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (122.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.5/122.5 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astpretty-3.0.0-py2.py3-none-any.whl (4.9 kB)\n",
      "Downloading cudensitymat_cu12-0.4.0-py3-none-manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading custatevec_cu12-1.12.0-py3-none-manylinux2014_x86_64.whl (73.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.2/73.2 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cutensornet_cu12-2.11.0-py3-none-manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cutensor_cu12-2.5.0-py3-none-manylinux2014_x86_64.whl (280.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: cudaq\n",
      "  Building wheel for cudaq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cudaq: filename=cudaq-0.13.0-py3-none-any.whl size=7002 sha256=2b95d4e231301d3db676328ed569e857af4c8228ab2bb7fe0b1dfef76c16b1d1\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/8a/10/ee10abd8723a2fbfd7962112962900ec48cbba4de11305846d\n",
      "Successfully built cudaq\n",
      "Installing collected packages: cutensor-cu12, custatevec-cu12, cutensornet-cu12, astpretty, cudensitymat-cu12, cuda-quantum-cu12, cudaq\n",
      "Successfully installed astpretty-3.0.0 cuda-quantum-cu12-0.13.0 cudaq-0.13.0 cudensitymat-cu12-0.4.0 custatevec-cu12-1.12.0 cutensor-cu12-2.5.0 cutensornet-cu12-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install cudaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QnvUafR3pRxt",
    "outputId": "009e0468-2096-4e54-b4f5-166e8ba385f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GPU.\n",
      "============================================================\n",
      "ðŸš€ FAST LABS QAOA v2.0 - N=30\n",
      "============================================================\n",
      "\n",
      "ðŸ” Endianness Sanity Check...\n",
      "  Prepared |100âŸ© (q0=1, q1=0, q2=0)\n",
      "  Got bitstring: '100'\n",
      "  âœ… Endianness: q0 is LEFTMOST (MSB) â†’ NO reversal needed\n",
      "\n",
      "ðŸš€ FastQAOAOptimizer v2.0 initialized:\n",
      "  N=30, p=1, seed=42\n",
      "  G2=210, G4=1925 (sample 962/iter)\n",
      "  Shots: 200 â†’ 500 (adaptive)\n",
      "  Elite pool: top-50\n",
      "\n",
      "â³ JIT warm-up (compiling kernels)...\n",
      "  âœ… Warm-up done in 16.1s\n",
      "\n",
      "--- Starting Fast QAOA (COBYLA, maxiter=80) ---\n",
      "  [10] E_avg=454.6, E_best=139, shots=254, elite=50, Cache: 0/2270 (0%)\n",
      "  [20] E_avg=405.5, E_best=139, shots=314, elite=50, Cache: 0/5140 (0%)\n",
      "  [30] E_avg=419.0, E_best=139, shots=374, elite=50, Cache: 0/8610 (0%)\n",
      "\n",
      "--- Complete in 200.4s ---\n",
      "  Circuit: 200.0s (100%)\n",
      "  Energy:  0.4s (0%)\n",
      "  Iters: 32\n",
      "  Best: E=139\n",
      "  Cache: 0/9376 (0%)\n",
      "\n",
      "--- Final Sampling (3000 shots, full G4) ---\n",
      "  Found 3000 new unique solutions\n",
      "  Best energy: 131\n",
      "\n",
      "--- Top 20 Elite Seeds ---\n",
      "  1. E=131\n",
      "  2. E=139\n",
      "  3. E=139\n",
      "  4. E=139\n",
      "  5. E=147\n",
      "  6. E=147\n",
      "  7. E=147\n",
      "  8. E=147\n",
      "  9. E=147\n",
      "  10. E=147\n",
      "\n",
      "============================================================\n",
      "âœ… FINAL: Best E = 131\n",
      "   Seeds ready for MTS: 20\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "QAOA for LABS - \"BugÃ¼n HÄ±zlandÄ±r\" v2.0 ðŸš€\n",
    "5 kritik dÃ¼zeltme:\n",
    "1. JIT warm-up (timing accuracy)\n",
    "2. Endianness sanity check\n",
    "3. Cache size limit (RAM safety)\n",
    "4. int8 dtype + int return\n",
    "5. NumPy RNG (reproducibility)\n",
    "\"\"\"\n",
    "\n",
    "import cudaq\n",
    "import numpy as np\n",
    "from math import floor\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "\n",
    "# Set GPU target\n",
    "try:\n",
    "    cudaq.set_target(\"nvidia\")\n",
    "    print(\"Using NVIDIA GPU.\")\n",
    "except:\n",
    "    print(\"Falling back to CPU.\")\n",
    "\n",
    "# =============================================================================\n",
    "# FIX 4: FAST ENERGY with int8 dtype\n",
    "# =============================================================================\n",
    "def calculate_labs_energy_fast(sequence):\n",
    "    \"\"\"Vectorized with int8 for speed.\"\"\"\n",
    "    s = np.asarray(sequence, dtype=np.int32)  # FIX 4: int8\n",
    "    n = len(s)\n",
    "    energy = np.int64(0)\n",
    "    for k in range(1, n):\n",
    "        c_k = np.dot(s[:n-k], s[k:])\n",
    "        energy += c_k * c_k\n",
    "    return int(energy)  # FIX 4: explicit int return\n",
    "\n",
    "# =============================================================================\n",
    "# FIX 2: ENDIANNESS SANITY CHECK\n",
    "# =============================================================================\n",
    "def verify_bitstring_endianness():\n",
    "    \"\"\"\n",
    "    Run once to verify bitstring ordering matches our assumption.\n",
    "    Tests with N=3 circuit.\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ” Endianness Sanity Check...\")\n",
    "\n",
    "    @cudaq.kernel\n",
    "    def test_kernel():\n",
    "        q = cudaq.qvector(3)\n",
    "        # Prepare |100âŸ© state (qubit 0 = |1âŸ©, others = |0âŸ©)\n",
    "        x(q[0])\n",
    "        mz(q)\n",
    "\n",
    "    results = cudaq.sample(test_kernel, shots_count=100)\n",
    "    most_common = max(results.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "    print(f\"  Prepared |100âŸ© (q0=1, q1=0, q2=0)\")\n",
    "    print(f\"  Got bitstring: '{most_common}'\")\n",
    "\n",
    "    # Check if q0 is rightmost (LSB) or leftmost (MSB)\n",
    "    if most_common == \"001\":\n",
    "        print(\"  âœ… Endianness: q0 is RIGHTMOST (LSB) â†’ use [::-1]\")\n",
    "        return True  # Need reversal\n",
    "    elif most_common == \"100\":\n",
    "        print(\"  âœ… Endianness: q0 is LEFTMOST (MSB) â†’ NO reversal needed\")\n",
    "        return False  # No reversal\n",
    "    else:\n",
    "        print(f\"  âš ï¸ Unexpected result, defaulting to [::-1]\")\n",
    "        return True\n",
    "\n",
    "# Global flag - set once at startup\n",
    "REVERSE_BITSTRING = None\n",
    "\n",
    "def bitstring_to_spins(bitstring):\n",
    "    \"\"\"Convert bitstring to spins with correct endianness.\"\"\"\n",
    "    global REVERSE_BITSTRING\n",
    "    if REVERSE_BITSTRING is None:\n",
    "        REVERSE_BITSTRING = verify_bitstring_endianness()\n",
    "\n",
    "    if REVERSE_BITSTRING:\n",
    "        return np.array([1 if b == '0' else -1 for b in bitstring[::-1]], dtype=np.int8)\n",
    "    else:\n",
    "        return np.array([1 if b == '0' else -1 for b in bitstring], dtype=np.int8)\n",
    "\n",
    "# =============================================================================\n",
    "# FIX 3: CACHE WITH SIZE LIMIT\n",
    "# =============================================================================\n",
    "class FastEnergyCache:\n",
    "    \"\"\"Cache with max size limit to prevent RAM explosion.\"\"\"\n",
    "\n",
    "    __slots__ = ['cache', 'hits', 'misses', 'max_size', 'clears']\n",
    "\n",
    "    def __init__(self, max_size=200_000):\n",
    "        self.cache = {}\n",
    "        self.max_size = max_size\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "        self.clears = 0\n",
    "\n",
    "    def get_energy(self, bitstring):\n",
    "        \"\"\"Fast path with size limit.\"\"\"\n",
    "        cached = self.cache.get(bitstring)\n",
    "        if cached is not None:\n",
    "            self.hits += 1\n",
    "            return cached\n",
    "\n",
    "        self.misses += 1\n",
    "        spins = bitstring_to_spins(bitstring)\n",
    "        energy = calculate_labs_energy_fast(spins)\n",
    "\n",
    "        # FIX 3: Clear if too large\n",
    "        if len(self.cache) >= self.max_size:\n",
    "            self.cache.clear()\n",
    "            self.clears += 1\n",
    "\n",
    "        self.cache[bitstring] = energy\n",
    "        return energy\n",
    "\n",
    "    def get_spins(self, bitstring):\n",
    "        \"\"\"Get spins for a bitstring.\"\"\"\n",
    "        return bitstring_to_spins(bitstring)\n",
    "\n",
    "    def stats(self):\n",
    "        total = self.hits + self.misses\n",
    "        if total == 0:\n",
    "            return \"Cache: empty\"\n",
    "        rate = 100 * self.hits / total\n",
    "        clr = f\", {self.clears} clears\" if self.clears else \"\"\n",
    "        return f\"Cache: {self.hits}/{total} ({rate:.0f}%){clr}\"\n",
    "\n",
    "# =============================================================================\n",
    "# INTERACTION GENERATION\n",
    "# =============================================================================\n",
    "def get_labs_interactions(N):\n",
    "    \"\"\"Generate G2 and G4 interactions.\"\"\"\n",
    "    G2 = []\n",
    "    G4 = []\n",
    "\n",
    "    for i in range(N - 2):\n",
    "        k_limit = floor((N - (i + 1)) / 2)\n",
    "        for k in range(1, k_limit + 1):\n",
    "            G2.append([i, i + k])\n",
    "\n",
    "    for i in range(N - 3):\n",
    "        t_limit = floor((N - (i + 1) - 1) / 2)\n",
    "        for t in range(1, t_limit + 1):\n",
    "            k_start = t + 1\n",
    "            k_end = N - (i + 1) - t\n",
    "            for k in range(k_start, k_end + 1):\n",
    "                G4.append([i, i + t, i + k, i + k + t])\n",
    "\n",
    "    return G2, G4\n",
    "\n",
    "# =============================================================================\n",
    "# QAOA KERNELS\n",
    "# =============================================================================\n",
    "@cudaq.kernel\n",
    "def r_zz(theta: float, q0: cudaq.qubit, q1: cudaq.qubit):\n",
    "    x.ctrl(q0, q1)\n",
    "    rz(theta, q1)\n",
    "    x.ctrl(q0, q1)\n",
    "\n",
    "@cudaq.kernel\n",
    "def r_4body_zzzz(theta: float, q0: cudaq.qubit, q1: cudaq.qubit,\n",
    "                  q2: cudaq.qubit, q3: cudaq.qubit):\n",
    "    x.ctrl(q0, q1)\n",
    "    x.ctrl(q1, q2)\n",
    "    x.ctrl(q2, q3)\n",
    "    rz(theta, q3)\n",
    "    x.ctrl(q2, q3)\n",
    "    x.ctrl(q1, q2)\n",
    "    x.ctrl(q0, q1)\n",
    "\n",
    "@cudaq.kernel\n",
    "def labs_qaoa_kernel(N: int, G2: list[list[int]], G4: list[list[int]],\n",
    "                     p_layers: int, gammas: list[float], betas: list[float]):\n",
    "    q = cudaq.qvector(N)\n",
    "    h(q)\n",
    "\n",
    "    for layer in range(p_layers):\n",
    "        gamma = gammas[layer]\n",
    "        beta = betas[layer]\n",
    "\n",
    "        for pair in G2:\n",
    "            r_zz(2.0 * gamma, q[pair[0]], q[pair[1]])\n",
    "\n",
    "        for quad in G4:\n",
    "            r_4body_zzzz(2.0 * gamma, q[quad[0]], q[quad[1]],\n",
    "                         q[quad[2]], q[quad[3]])\n",
    "\n",
    "        for i in range(N):\n",
    "            rx(2.0 * beta, q[i])\n",
    "\n",
    "    mz(q)\n",
    "\n",
    "@cudaq.kernel\n",
    "def labs_qaoa_kernel_minibatch(N: int, G2: list[list[int]], G4_subset: list[list[int]],\n",
    "                                p_layers: int, gammas: list[float], betas: list[float]):\n",
    "    \"\"\"Same kernel but accepts a subset of G4 terms.\"\"\"\n",
    "    q = cudaq.qvector(N)\n",
    "    h(q)\n",
    "\n",
    "    for layer in range(p_layers):\n",
    "        gamma = gammas[layer]\n",
    "        beta = betas[layer]\n",
    "\n",
    "        for pair in G2:\n",
    "            r_zz(2.0 * gamma, q[pair[0]], q[pair[1]])\n",
    "\n",
    "        for quad in G4_subset:\n",
    "            r_4body_zzzz(2.0 * gamma, q[quad[0]], q[quad[1]],\n",
    "                         q[quad[2]], q[quad[3]])\n",
    "\n",
    "        for i in range(N):\n",
    "            rx(2.0 * beta, q[i])\n",
    "\n",
    "    mz(q)\n",
    "\n",
    "# =============================================================================\n",
    "# FAST QAOA OPTIMIZER v2.0\n",
    "# =============================================================================\n",
    "class FastQAOAOptimizer:\n",
    "    \"\"\"\n",
    "    QAOA with all optimizations + 5 critical fixes:\n",
    "    1. JIT warm-up\n",
    "    2. Endianness verified\n",
    "    3. Cache size limit\n",
    "    4. int8 dtype\n",
    "    5. NumPy RNG\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N, p_layers=1,\n",
    "                 shots_init=200, shots_max=500,\n",
    "                 g4_sample_ratio=0.5,\n",
    "                 elite_k=50,\n",
    "                 seed=42):  # FIX 5: reproducibility\n",
    "\n",
    "        self.N = N\n",
    "        self.p_layers = p_layers\n",
    "\n",
    "        # Adaptive shots\n",
    "        self.shots_init = shots_init\n",
    "        self.shots_max = shots_max\n",
    "        self.shots_current = shots_init\n",
    "\n",
    "        # G4 minibatch\n",
    "        self.G2, self.G4_full = get_labs_interactions(N)\n",
    "        self.g4_sample_ratio = g4_sample_ratio\n",
    "        self.g4_sample_size = max(1, int(len(self.G4_full) * g4_sample_ratio))\n",
    "\n",
    "        # FIX 5: NumPy RNG for reproducibility\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        # FIX 3: Cache with size limit\n",
    "        self.energy_cache = FastEnergyCache(max_size=200_000)\n",
    "\n",
    "        # Elite tracking (top-K)\n",
    "        self.elite_k = elite_k\n",
    "        self.elite_solutions = {}\n",
    "\n",
    "        # Global best\n",
    "        self.global_best_energy = float('inf')\n",
    "        self.global_best_params = None\n",
    "        self.global_best_bitstring = None\n",
    "\n",
    "        # Tracking\n",
    "        self.iteration = 0\n",
    "        self.cost_history = []\n",
    "        self.best_energy_history = []\n",
    "\n",
    "        # Timing (excluding warm-up)\n",
    "        self.total_circuit_time = 0\n",
    "        self.total_energy_time = 0\n",
    "\n",
    "        print(f\"\\nðŸš€ FastQAOAOptimizer v2.0 initialized:\")\n",
    "        print(f\"  N={N}, p={p_layers}, seed={seed}\")\n",
    "        print(f\"  G2={len(self.G2)}, G4={len(self.G4_full)} (sample {self.g4_sample_size}/iter)\")\n",
    "        print(f\"  Shots: {shots_init} â†’ {shots_max} (adaptive)\")\n",
    "        print(f\"  Elite pool: top-{elite_k}\")\n",
    "\n",
    "    # FIX 1: JIT WARM-UP\n",
    "    def warmup(self):\n",
    "        \"\"\"Trigger JIT compilation before timing starts.\"\"\"\n",
    "        print(\"\\nâ³ JIT warm-up (compiling kernels)...\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        gammas = [0.2] * self.p_layers\n",
    "        betas = [0.4] * self.p_layers\n",
    "        G4_subset = self._sample_g4()\n",
    "\n",
    "        # Compile both kernels\n",
    "        cudaq.sample(\n",
    "            labs_qaoa_kernel_minibatch,\n",
    "            self.N, self.G2, G4_subset,\n",
    "            self.p_layers, gammas, betas,\n",
    "            shots_count=64\n",
    "        )\n",
    "        cudaq.sample(\n",
    "            labs_qaoa_kernel,\n",
    "            self.N, self.G2, self.G4_full,\n",
    "            self.p_layers, gammas, betas,\n",
    "            shots_count=64\n",
    "        )\n",
    "\n",
    "        print(f\"  âœ… Warm-up done in {time.time()-t0:.1f}s\")\n",
    "\n",
    "    # FIX 5: NumPy RNG for G4 sampling\n",
    "    def _sample_g4(self):\n",
    "        \"\"\"Random subset of G4 terms using NumPy RNG.\"\"\"\n",
    "        if self.g4_sample_ratio >= 1.0:\n",
    "            return self.G4_full\n",
    "        idx = self.rng.choice(len(self.G4_full), size=self.g4_sample_size, replace=False)\n",
    "        return [self.G4_full[i] for i in idx]\n",
    "\n",
    "    def _update_shots(self):\n",
    "        \"\"\"Increase shots as optimization progresses.\"\"\"\n",
    "        progress = min(1.0, self.iteration / 50)\n",
    "        self.shots_current = int(self.shots_init + progress * (self.shots_max - self.shots_init))\n",
    "\n",
    "    def _update_elite(self, bitstring, energy):\n",
    "        \"\"\"Keep only top-K elite solutions.\"\"\"\n",
    "        if len(self.elite_solutions) < self.elite_k:\n",
    "            self.elite_solutions[bitstring] = (energy, self.iteration)\n",
    "        else:\n",
    "            worst_bs = max(self.elite_solutions, key=lambda x: self.elite_solutions[x][0])\n",
    "            worst_energy = self.elite_solutions[worst_bs][0]\n",
    "\n",
    "            if energy < worst_energy:\n",
    "                del self.elite_solutions[worst_bs]\n",
    "                self.elite_solutions[bitstring] = (energy, self.iteration)\n",
    "\n",
    "    def cost_function(self, params):\n",
    "        \"\"\"Evaluate with all optimizations.\"\"\"\n",
    "        gammas = list(params[:self.p_layers])\n",
    "        betas = list(params[self.p_layers:])\n",
    "\n",
    "        self._update_shots()\n",
    "        G4_subset = self._sample_g4()\n",
    "\n",
    "        # Circuit execution (timing is now accurate after warm-up)\n",
    "        t0 = time.time()\n",
    "        results = cudaq.sample(\n",
    "            labs_qaoa_kernel_minibatch,\n",
    "            self.N, self.G2, G4_subset,\n",
    "            self.p_layers, gammas, betas,\n",
    "            shots_count=self.shots_current\n",
    "        )\n",
    "        self.total_circuit_time += time.time() - t0\n",
    "\n",
    "        # Energy calculation\n",
    "        t0 = time.time()\n",
    "        total_energy = 0.0\n",
    "        total_counts = 0\n",
    "\n",
    "        for bitstring, count in results.items():\n",
    "            energy = self.energy_cache.get_energy(bitstring)\n",
    "            total_energy += energy * count\n",
    "            total_counts += count\n",
    "\n",
    "            self._update_elite(bitstring, energy)\n",
    "\n",
    "            if energy < self.global_best_energy:\n",
    "                self.global_best_energy = energy\n",
    "                self.global_best_params = np.array(params).copy()\n",
    "                self.global_best_bitstring = bitstring\n",
    "\n",
    "        self.total_energy_time += time.time() - t0\n",
    "\n",
    "        expected_energy = total_energy / total_counts\n",
    "\n",
    "        self.iteration += 1\n",
    "        self.cost_history.append(expected_energy)\n",
    "        self.best_energy_history.append(self.global_best_energy)\n",
    "\n",
    "        if self.iteration % 10 == 0:\n",
    "            print(f\"  [{self.iteration}] E_avg={expected_energy:.1f}, \"\n",
    "                  f\"E_best={self.global_best_energy:.0f}, \"\n",
    "                  f\"shots={self.shots_current}, \"\n",
    "                  f\"elite={len(self.elite_solutions)}, \"\n",
    "                  f\"{self.energy_cache.stats()}\")\n",
    "\n",
    "        return expected_energy\n",
    "\n",
    "    def optimize(self, method='COBYLA', maxiter=100, initial_params=None):\n",
    "        \"\"\"Run optimization with warm-up.\"\"\"\n",
    "        # FIX 1: Warm-up before timing\n",
    "        self.warmup()\n",
    "\n",
    "        print(f\"\\n--- Starting Fast QAOA ({method}, maxiter={maxiter}) ---\")\n",
    "\n",
    "        if initial_params is None:\n",
    "            initial_params = np.concatenate([\n",
    "                np.linspace(0.1, 0.5, self.p_layers),\n",
    "                np.linspace(0.3, 0.7, self.p_layers)\n",
    "            ])\n",
    "\n",
    "        t_start = time.time()\n",
    "\n",
    "        result = minimize(\n",
    "            self.cost_function,\n",
    "            initial_params,\n",
    "            method=method,\n",
    "            options={'maxiter': maxiter}\n",
    "        )\n",
    "\n",
    "        total_time = time.time() - t_start\n",
    "\n",
    "        print(f\"\\n--- Complete in {total_time:.1f}s ---\")\n",
    "        print(f\"  Circuit: {self.total_circuit_time:.1f}s ({100*self.total_circuit_time/total_time:.0f}%)\")\n",
    "        print(f\"  Energy:  {self.total_energy_time:.1f}s ({100*self.total_energy_time/total_time:.0f}%)\")\n",
    "        print(f\"  Iters: {self.iteration}\")\n",
    "        print(f\"  Best: E={self.global_best_energy:.0f}\")\n",
    "        print(f\"  {self.energy_cache.stats()}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_elite_seeds(self, top_k=20):\n",
    "        \"\"\"Get top solutions as MTS seeds.\"\"\"\n",
    "        sorted_elite = sorted(\n",
    "            self.elite_solutions.items(),\n",
    "            key=lambda x: x[1][0]\n",
    "        )[:top_k]\n",
    "\n",
    "        print(f\"\\n--- Top {min(top_k, len(sorted_elite))} Elite Seeds ---\")\n",
    "        seeds = []\n",
    "        for i, (bitstring, (energy, _)) in enumerate(sorted_elite):\n",
    "            spins = self.energy_cache.get_spins(bitstring)\n",
    "            seeds.append(list(spins))\n",
    "            if i < 10:\n",
    "                print(f\"  {i+1}. E={energy:.0f}\")\n",
    "\n",
    "        return seeds\n",
    "\n",
    "    def final_sampling(self, shots=2000):\n",
    "        \"\"\"High-shot sampling with best params.\"\"\"\n",
    "        if self.global_best_params is None:\n",
    "            print(\"Run optimize() first!\")\n",
    "            return []\n",
    "\n",
    "        print(f\"\\n--- Final Sampling ({shots} shots, full G4) ---\")\n",
    "\n",
    "        gammas = list(self.global_best_params[:self.p_layers])\n",
    "        betas = list(self.global_best_params[self.p_layers:])\n",
    "\n",
    "        results = cudaq.sample(\n",
    "            labs_qaoa_kernel,\n",
    "            self.N, self.G2, self.G4_full,\n",
    "            self.p_layers, gammas, betas,\n",
    "            shots_count=shots\n",
    "        )\n",
    "\n",
    "        new_elites = 0\n",
    "        for bitstring, count in results.items():\n",
    "            energy = self.energy_cache.get_energy(bitstring)\n",
    "\n",
    "            if bitstring not in self.elite_solutions:\n",
    "                self._update_elite(bitstring, energy)\n",
    "                new_elites += 1\n",
    "\n",
    "            if energy < self.global_best_energy:\n",
    "                self.global_best_energy = energy\n",
    "                self.global_best_bitstring = bitstring\n",
    "\n",
    "        print(f\"  Found {new_elites} new unique solutions\")\n",
    "        print(f\"  Best energy: {self.global_best_energy:.0f}\")\n",
    "\n",
    "        return self.get_elite_seeds()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    N = 30\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ðŸš€ FAST LABS QAOA v2.0 - N={N}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # FIX 2: Verify endianness once at startup\n",
    "    _ = bitstring_to_spins(\"000\")  # Triggers check\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = FastQAOAOptimizer(\n",
    "        N=N,\n",
    "        p_layers=1,\n",
    "        shots_init=200,\n",
    "        shots_max=500,\n",
    "        g4_sample_ratio=0.5,\n",
    "        elite_k=50,\n",
    "        seed=42  # Reproducible\n",
    "    )\n",
    "\n",
    "    # Optimize\n",
    "    result = optimizer.optimize(method='COBYLA', maxiter=80)\n",
    "\n",
    "    # Final high-quality sampling\n",
    "    seeds = optimizer.final_sampling(shots=3000)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"âœ… FINAL: Best E = {optimizer.global_best_energy}\")\n",
    "    print(f\"   Seeds ready for MTS: {len(seeds)}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 000 | En Ä°yi Enerji: 83.0\n",
      "Gen 010 | En Ä°yi Enerji: 83.0\n",
      "Gen 020 | En Ä°yi Enerji: 83.0\n",
      "Gen 030 | En Ä°yi Enerji: 75.0\n",
      "Gen 040 | En Ä°yi Enerji: 75.0\n",
      "Gen 050 | En Ä°yi Enerji: 75.0\n",
      "Gen 060 | En Ä°yi Enerji: 75.0\n",
      "Gen 070 | En Ä°yi Enerji: 75.0\n",
      "Gen 080 | En Ä°yi Enerji: 75.0\n",
      "Gen 090 | En Ä°yi Enerji: 75.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import cupy as cp\n",
    "    DEVICE = \"GPU (CuPy)\"\n",
    "except ImportError:\n",
    "    import numpy as cp\n",
    "    DEVICE = \"CPU (NumPy)\"\n",
    "\n",
    "def calculate_energy_fft(sequences):\n",
    "    \"\"\"\n",
    "    LABS probleminin enerji fonksiyonu: E = sum_{k=1}^{N-1} (C_k)^2\n",
    "    Wiener-Khinchin teoremi kullanÄ±larak O(N log N) hÄ±zÄ±nda hesaplanÄ±r.\n",
    "    \"\"\"\n",
    "    if sequences.ndim == 1:\n",
    "        sequences = sequences.reshape(1, -1)\n",
    "\n",
    "    batch_size, N = sequences.shape\n",
    "    # FFT hÄ±zÄ± iÃ§in en yakÄ±n 2'nin kuvvetine tamamla\n",
    "    n_fft = 2**((2 * N - 1).bit_length())\n",
    "\n",
    "    # Fourier DÃ¶nÃ¼ÅŸÃ¼mÃ¼ ile otokorelasyon hesabÄ±\n",
    "    f_seq = cp.fft.rfft(sequences, n=n_fft, axis=1)\n",
    "    autocorr = cp.fft.irfft(f_seq * cp.conj(f_seq), n=n_fft, axis=1)\n",
    "\n",
    "    # k=1'den N-1'e kadar olan kÄ±sÄ±mlarÄ±n kareleri toplamÄ± (C_k^2)\n",
    "    # cp.round kullanÄ±yoruz Ã§Ã¼nkÃ¼ FFT float sonuÃ§ dÃ¶ner, LABS tam sayÄ±dÄ±r.\n",
    "    energies = cp.sum(cp.round(autocorr[:, 1:N])**2, axis=1)\n",
    "    return energies\n",
    "\n",
    "# --- [STEP 3: PARALEL ADAY LÄ°STELÄ° TABU SEARCH (EDUCATION)] ---\n",
    "def tabu_search_gpu(initial_seq, max_iters=30, tabu_tenure=7):\n",
    "    \"\"\"\n",
    "    Yerel arama adÄ±mÄ±. GPU'da tÃ¼m komÅŸularÄ± aynÄ± anda deÄŸerlendirir.\n",
    "    \"\"\"\n",
    "    N = len(initial_seq)\n",
    "    current_seq = cp.array(initial_seq)\n",
    "    current_energy = calculate_energy_fft(current_seq)[0]\n",
    "\n",
    "    best_seq = current_seq.copy()\n",
    "    best_energy = current_energy\n",
    "    tabu_list = cp.zeros(N, dtype=cp.int32)\n",
    "\n",
    "    for it in range(max_iters):\n",
    "        # TÃ¼m 1-bit flip komÅŸularÄ± tek bir matriste oluÅŸtur (N, N)\n",
    "        neighbors = cp.tile(current_seq, (N, 1))\n",
    "        diag_indices = cp.arange(N)\n",
    "        neighbors[diag_indices, diag_indices] *= -1\n",
    "\n",
    "        # Enerjileri toplu halde (batch) hesapla\n",
    "        neighbor_energies = calculate_energy_fft(neighbors)\n",
    "\n",
    "        # Tabu durumu ve Aspiration (En iyiyi geÃ§iyorsa yasaÄŸÄ± del)\n",
    "        is_not_tabu = (tabu_list <= it)\n",
    "        is_aspiration = (neighbor_energies < best_energy)\n",
    "        mask = is_not_tabu | is_aspiration\n",
    "\n",
    "        neighbor_energies[~mask] = cp.inf\n",
    "\n",
    "        # En iyi hareketi seÃ§\n",
    "        best_move_idx = cp.argmin(neighbor_energies)\n",
    "        current_seq = neighbors[best_move_idx]\n",
    "        current_energy = neighbor_energies[best_move_idx]\n",
    "\n",
    "        if current_energy < best_energy:\n",
    "            best_energy = current_energy\n",
    "            best_seq = current_seq.copy()\n",
    "\n",
    "        # Hamleyi yasaklÄ±lar listesine ekle\n",
    "        tabu_list[best_move_idx] = it + tabu_tenure\n",
    "\n",
    "    return best_seq, float(best_energy)\n",
    "\n",
    "# --- [STEP 4: ANA MEMETÄ°K TABU SEARCH DÃ–NGÃœSÃœ] ---\n",
    "def run_full_mts(N=64, pop_size=20, generations=50, p_mutate=0.2, initial_population = None):\n",
    "    \"\"\"\n",
    "    Memetik algoritmanÄ±n ana dÃ¶ngÃ¼sÃ¼: Combine -> Mutate -> Educate\n",
    "    \"\"\"\n",
    "    # PopÃ¼lasyonu baÅŸlat (Ä°leride buraya Kuantum Seeds eklenebilir)\n",
    "    if initial_population is not None:\n",
    "            # ArkadaÅŸÄ±ndan gelen listeyi GPU matrisine Ã§evir\n",
    "            quantum_pop = cp.array(initial_population)\n",
    "\n",
    "            # EÄŸer kuantumdan gelen dizi sayÄ±sÄ± pop_size'dan kÃ¼Ã§Ã¼kse geri kalanÄ± rastgele doldur\n",
    "            if len(quantum_pop) < pop_size:\n",
    "                extra_count = pop_size - len(quantum_pop)\n",
    "                extra_pop = cp.random.choice(cp.array([-1, 1]), (extra_count, N))\n",
    "                population = cp.vstack([quantum_pop, extra_pop])\n",
    "            else:\n",
    "                # EÄŸer kuantumdan Ã§ok fazla dizi gelirse en iyilerini/ilklerini al\n",
    "                population = quantum_pop[:pop_size]\n",
    "    else:\n",
    "            # DÄ±ÅŸarÄ±dan veri gelmezse tamamen rastgele baÅŸlat\n",
    "        population = cp.random.choice(cp.array([-1, 1]), (pop_size, N))\n",
    "\n",
    "    global_best_seq = None\n",
    "    global_best_energy = float('inf')\n",
    "    history = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for gen in range(generations):\n",
    "        # 1. COMBINE (Crossover): 3 ebeveynden Ã§oÄŸunluk oyu\n",
    "        idx = cp.random.choice(pop_size, 3, replace=False)\n",
    "        child = cp.sign(cp.sum(population[idx], axis=0))\n",
    "        child[child == 0] = 1\n",
    "\n",
    "        # 2. MUTATE: Rastgele bit Ã§evirme\n",
    "        if cp.random.random() < p_mutate:\n",
    "            m_point = cp.random.randint(0, N)\n",
    "            child[m_point] *= -1\n",
    "\n",
    "        # 3. EDUCATION: Tabu Search ile yerel iyileÅŸtirme\n",
    "        improved_child, improved_energy = tabu_search_gpu(child)\n",
    "\n",
    "        # 4. SELECTION: PopÃ¼lasyondaki en kÃ¶tÃ¼nÃ¼n yerine koy (Steady-state update)\n",
    "        pop_energies = calculate_energy_fft(population)\n",
    "        worst_idx = cp.argmax(pop_energies)\n",
    "\n",
    "        if improved_energy < pop_energies[worst_idx]:\n",
    "            population[worst_idx] = improved_child\n",
    "\n",
    "        # Global Best GÃ¼ncelleme\n",
    "        if improved_energy < global_best_energy:\n",
    "            global_best_energy = improved_energy\n",
    "            global_best_seq = improved_child.copy()\n",
    "\n",
    "        history.append(global_best_energy)\n",
    "        if gen % 10 == 0:\n",
    "            print(f\"Gen {gen:03d} | En Ä°yi Enerji: {global_best_energy:.1f}\")\n",
    "\n",
    "    total_duration = time.time() - start_time\n",
    "    return global_best_seq, global_best_energy, total_duration, history\n",
    "best_sol, best_en, duration, hist = run_full_mts(N=N, generations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 2: Classical Optimization (Hybrid) ---\n",
      "Starting MTS with Quantum-Seeded Population...\n",
      "Gen 000 | En Ä°yi Enerji: 99.0\n",
      "Gen 010 | En Ä°yi Enerji: 75.0\n",
      "Gen 020 | En Ä°yi Enerji: 75.0\n",
      "Gen 030 | En Ä°yi Enerji: 75.0\n",
      "Gen 040 | En Ä°yi Enerji: 75.0\n",
      "\n",
      "--- Final Results ---\n",
      "Best Energy Found: 75.0\n",
      "Best Sequence: [-1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1 -1  1  1 -1 -1  1 -1 -1  1  1 -1  1\n",
      " -1  1 -1 -1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "# 5. RUN HYBRID MEMETIC TABU SEARCH\n",
    "print(f\"\\n--- Phase 2: Classical Optimization (Hybrid) ---\")\n",
    "print(\"Starting MTS with Quantum-Seeded Population...\")\n",
    "\n",
    "# Run MTS using the quantum seeds\n",
    "best_seq, best_energy, final_pop, history = run_full_mts(\n",
    "    N=N,\n",
    "    pop_size=len(seeds),   # Match population size to our seeds\n",
    "    generations=50,\n",
    "    initial_population=seeds # <--- INJECT QUANTUM DATA HERE\n",
    ")\n",
    "# 6. REPORT RESULTS\n",
    "print(\"\\n--- Final Results ---\")\n",
    "print(f\"Best Energy Found: {best_energy}\")\n",
    "print(f\"Best Sequence: {best_seq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [cuda-q-v0.13.0]",
   "language": "python",
   "name": "python3_48iu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
